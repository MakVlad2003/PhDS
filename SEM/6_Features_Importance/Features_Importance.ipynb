{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "be8a1d98"
   },
   "source": [
    "# ML в Биологии\n",
    "## Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "68e524ec5a9cae96"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "6b132fcd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "21602547",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Рассмотрим как можно провести отбор признаков с помощью обучения линейной регрессии и леса с малым количеством деревьев ($\\approx 10$) на примере задачи регрессии. Будем использовать датасет <https://www.kaggle.com/datasets/abrambeyer/openintro-possum> и пытаться предсказать возраст оппосумов на основе различных параметров их тела.\n",
    "\n",
    "Для упрощения задачи избавимся от категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGcdT3zQklXG",
    "outputId": "f09f8240-9854-41bf-83cc-00f1fd2f4f25"
   },
   "outputs": [],
   "source": [
    "!unzip archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "e33ab772",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('possum.csv').dropna()\n",
    "X = data[data.columns.drop(['sex', 'Pop', 'age'])]\n",
    "y = data['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "ad2ecc9d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Разделим выборку на тренировочную и тестовую часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "8654d280",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "8f7cdd4e",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Стандартизируем данные для корректной работы **линейной регрессии**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "15160c3f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "518281a3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обучим модель линейной регрессии с L1-регуляризацией на всех данных, посмотрим на метрику качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6410500",
    "outputId": "3d212b4c-e36e-4e55-cb91-b67af8e1cfbe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lin_model = Lasso(alpha=0.05, fit_intercept=True).fit(X_train_norm, y_train)\n",
    "print('Коэффициенты модели:', lin_model.coef_)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(lin_model.predict(X_train_norm), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(lin_model.predict(X_test_norm), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "ffc918fd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Проделаем аналогичную процедуру с лесом c небольшим количеством деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ae946f2",
    "outputId": "fe205f47-8155-4351-9b6c-490b796d5590",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor().fit(X_train_norm, y_train)\n",
    "print('Важность признаков:', forest.feature_importances_)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(forest.predict(X_train), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(forest.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "a7284a11"
   },
   "source": [
    "Что вы можете сказать смотря на коэффициенты модели для регрессии и на важность признаков для леса?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "1042359e"
   },
   "source": [
    "**Вывод**:\n",
    "\n",
    "Видно, что не все параметры для важны. Некоторые из них оказывают большее влияние. Такая тенденция видна и в лесу, и в регрессии. Чем меньше параметр - тем меньше его важность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "89a4694e",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Составим 2 списка наиболее важных признаков - один с признаками, наиболее важными для линейной регрессии, второй с наиболее важными для леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "13a25ff0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lin_imp = []\n",
    "forest_imp = []\n",
    "for i, column in enumerate(X.columns):\n",
    "    if lin_model.coef_[i] > 0.1:\n",
    "        lin_imp.append(i)\n",
    "    if forest.feature_importances_[i] > 0.1:\n",
    "        forest_imp.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "a7b269c4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_norm_lin_imp = X_train_norm[:, lin_imp]\n",
    "X_test_norm_lin_imp = X_test_norm[:, lin_imp]\n",
    "\n",
    "X_train_forest_imp = X_train[forest_imp]\n",
    "X_test_forest_imp = X_test[forest_imp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "07705dd7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь обучим модели только на важных признаках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d54368",
    "outputId": "f8ae889f-15b9-4163-859d-7b9c027fdac3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lin_model_2 = Lasso(alpha=0.01, fit_intercept=True).fit(X_train_norm_lin_imp, y_train)\n",
    "print('Коэффиценты модели:', lin_model.coef_)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(lin_model_2.predict(X_train_norm_lin_imp), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(lin_model_2.predict(X_test_norm_lin_imp), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4f0c848",
    "outputId": "49432b98-ca68-4590-fea3-fc7c75df2c42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest_2 = RandomForestRegressor().fit(X_train_forest_imp, y_train)\n",
    "print('Важность признаков:', forest.feature_importances_)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(forest_2.predict(X_train_forest_imp), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(forest_2.predict(X_test_forest_imp), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "e2995fae"
   },
   "source": [
    "Что вы можете сказать о качестве предсказания?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "c7febc6a"
   },
   "source": [
    "**Вывод:**\n",
    "\n",
    "В линейной регрессии не сильно изменилась метрика. С помощью L1-регуляризации мы отбираем важные признаки. А вот лес стал гораздо лучше предсказывать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "153779c7"
   },
   "source": [
    "Рассмотрим работу других метотодов оценки важности признаков, а именно *Permutation feature importance* и *Column feature importance*,на примере [KNN-регресии](https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html).\n",
    "\n",
    "Для корректной работы KNN необходимо стандартизовать признаки, как мы это делали для Lasso-регресии. А также разделить тренировачный датасет на train и val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "b95d6ab1"
   },
   "outputs": [],
   "source": [
    "X_train_norm, X_val_norm, y_train, y_val = train_test_split(X_train_norm, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3f5cf99",
    "outputId": "b944af9b-789b-4aee-beea-6cc3e5872095"
   },
   "outputs": [],
   "source": [
    "knn_1 = KNeighborsRegressor(n_neighbors=5).fit(X_train_norm, y_train)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(knn_1.predict(X_train_norm), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(knn_1.predict(X_test_norm), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "id": "e0a3e710"
   },
   "source": [
    "**Permutation feature importance** полностью реализован в `sklearn.inspection`\n",
    "\n",
    "\n",
    "Функция `permutation_importance()` принимает на вход:\n",
    "- `model` &mdash; обученная модель\n",
    "- `X, y` &mdash;  фичи и таргет валидационной части датасета\n",
    "- `n_repeats` &mdash; сколько раз переставляется фича\n",
    "\n",
    "На выходе мы получаем:\n",
    "- `importances` &mdash сырые оценки значимости для всех фичей и всех итераций\n",
    "- `importances_mean` &mdash; среднее по всем итерациям\n",
    "- `importances_std` &mdash; стандартоное отклонение среднего"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "a4b8361a"
   },
   "source": [
    "Оценим важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "71ee53d1"
   },
   "outputs": [],
   "source": [
    "r = permutation_importance(knn_1, X_val_norm, y_val, n_repeats=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "49c61e73"
   },
   "source": [
    "Отберем признаки согласно нашей оценке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "c5953352"
   },
   "outputs": [],
   "source": [
    "knn_imp = []\n",
    "for i, column in enumerate(X.columns):\n",
    "    if r.importances_mean[i] - r.importances_std[i] >= 0:\n",
    "        knn_imp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "b05d1b4f"
   },
   "outputs": [],
   "source": [
    "X_train_norm_knn_imp = X_train_norm[:, knn_imp]\n",
    "X_test_norm_knn_imp = X_test_norm[:, knn_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "984ddad8",
    "outputId": "a6056220-c321-4b95-b196-be67aa76ffa0"
   },
   "outputs": [],
   "source": [
    "knn_2 = KNeighborsRegressor(n_neighbors=5).fit(X_train_norm_knn_imp, y_train)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(knn_2.predict(X_train_norm_knn_imp), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(knn_2.predict(X_test_norm_knn_imp), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "557d9ce7"
   },
   "source": [
    "**Drop-Column feature importance**\n",
    "\n",
    "Для него готовой реализации в `sklearn` нет, так что воспольлзуемся кодом ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "fc007092"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5).fit(X_train_norm, y_train)\n",
    "baseline = MSE(knn.predict(X_val_norm), y_val)\n",
    "knn_imp = []\n",
    "\n",
    "for i, column in enumerate(X.columns):\n",
    "    X_train_drop = np.delete(X_train_norm, i, 1)\n",
    "    X_val_drop =  np.delete(X_val_norm, i , 1)\n",
    "\n",
    "    knn_drop = KNeighborsRegressor(n_neighbors=5).fit(X_train_drop, y_train)\n",
    "\n",
    "    mse = MSE(knn_drop.predict(X_val_drop), y_val)\n",
    "\n",
    "    if ((mse - baseline) / baseline) > 0.1:\n",
    "        knn_imp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "195382df"
   },
   "outputs": [],
   "source": [
    "X_train_norm_knn_imp = X_train_norm[:, knn_imp]\n",
    "X_test_norm_knn_imp = X_test_norm[:, knn_imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5069ad04",
    "outputId": "55af517a-4360-4daa-c304-717e5efef516"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5).fit(X_train_norm_knn_imp, y_train)\n",
    "print('Значение MSE на тренировочной выборке:', MSE(knn.predict(X_train_norm_knn_imp), y_train))\n",
    "print('Значение MSE на тестовой выборке:', MSE(knn.predict(X_test_norm_knn_imp), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "858225b9"
   },
   "source": [
    "**Вывод:**\n",
    "\n",
    "После permutation метрика на KNN ухудшается,а на Drop Column метрика меняется незначительно. Вероятно, что удаляется слишком много признаков и это как-то можно исправить более тщательным анализом и настройкой фичей."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
