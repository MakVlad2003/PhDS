{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Batch Normalization, lightning, логгирование экспериментов\n",
    "\n",
    "Цель этого ноутбука -- знакомство с фреймворком PyTorch Lightning, который предназначен для автоматизации и упрощения использования PyTorch\n",
    "\n",
    " План семинара:\n",
    "\n",
    "* BatchNormalization\n",
    "* PyTorch Lightning\n",
    "* Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "\n",
    "# device_num = 0\n",
    "# torch.cuda.set_device(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. [Batch Normalization (BN)](http://arxiv.org/abs/1502.03167)\n",
    "Идея batch normalization на самом деле содержится в самом названии &mdash;\n",
    "**будем нормализовать выход каждого слоя**: вычитать из значения каждого признака\n",
    "среднее его значение по текущему батчу и делить на стандартное отклонение. После этого значения признаков умножаются на обучаемый параметр `gamma` и прибавляется обучаемый свободный член `beta`, что позволяет \"контролировать\" среднее значение и дисперсию признаков.\n",
    "\n",
    "*Forward pass:*\n",
    "\n",
    "$$\n",
    "x \\in \\mathbb{R}^{n \\times d}\n",
    "$$\n",
    "$$\n",
    "\\mu, \\sigma, \\gamma, \\beta \\in \\mathbb{R}^{1 \\times d}\n",
    "$$\n",
    "\n",
    "В фазе обучения  (`self.training == True`) BatchNormalization слой делает то, что описано выше:\n",
    "\n",
    "$$\n",
    "\\text{BatchNormalization}(x) = \\gamma \\left( \\frac{x - \\mu}{\\sqrt{\\sigma + \\varepsilon}} \\right) + \\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{BatchNormalization}(x) \\in \\mathbb{R}^{n \\times d}\n",
    "$$\n",
    "\n",
    "где\n",
    "* $\\mu$ и $\\sigma$ &mdash; среднее и дисперсия значений признаков в $x$,\n",
    "* $\\varepsilon$ нужен чтобы избежать деление на машинный 0,\n",
    "* $\\gamma$ и $\\beta$ &mdash; обучаемые параметры.\n",
    "\n",
    "Также в фазе обучения среднее и дисперсию признаков обновляют (moving average):\n",
    "\n",
    "```\n",
    "    self.moving_mean = self.moving_mean * alpha + batch_mean * (1 - alpha)\n",
    "    self.moving_variance = self.moving_variance * alpha + batch_variance * (1 - alpha)\n",
    "```\n",
    "\n",
    "В фазе применения нейросети (`self.training == False`) слой нормализует вход `input`, используя посчитанные в фазе обучения `moving_mean` и `moving_variance`.\n",
    "\n",
    "На практике BatchNorm обычно ускоряет сходимость при оптимизации, то есть позволяет обучать нейросети быстрее. Но, как обычно в нейронных сетях, эффективность нужно проверять на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Lightning\n",
    "\n",
    "Полезные ссылки:\n",
    "\n",
    "[Docs](https://lightning.ai/docs/pytorch/stable/starter/installation.html)\n",
    "\n",
    "[Lightning Universe](https://github.com/Lightning-Universe) (Комьюнити проекты, расширения и доп возможности)\n",
    "\n",
    "[Lightning Flash](https://github.com/Lightning-Universe/lightning-flash) (Зоопарк готовых моделей)\n",
    "\n",
    "[Lightning Bolts](https://lightning-bolts.readthedocs.io/en/latest/) (Еще один зоопарк моделей, датасетов и супер-коллбеков)\n",
    "\n",
    "[Train model with billions of parameters](https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html)\n",
    "\n",
    "### Intro\n",
    "Мир обучения нейронок уже давно перешагнул за `train_loop(...)`, `optimizer.step()`, ..., `zero_grad`, ...,\n",
    "и ровно как вы не дергаете Cuda из питона и не пишите полносвязные слои руками, ровно так же не стоит писать тренировку модели руками, потому что:\n",
    "- Это долго\n",
    "- Это баговано\n",
    "- Каждый раз одно и то же\n",
    "- Множество вещей вы просто не знаете как написать (и это нормально!)\n",
    "- Поддерживать простыню кода в тысячи сток просто невозможно, если вы не мазохист\n",
    "- Процесс добавления распределенного обучения для вас станет последней ступенью ада\n",
    "\n",
    "Есть несколько фреймворков, которые решают перечисленные выше проблемы. Это Catalyst, PyTorch Lightning, PyTorch Ignite.\n",
    "\n",
    "Далее речь пойдет именно о Lightning. \n",
    "\n",
    "### Установка\n",
    "\n",
    "[Installation Guide](https://lightning.ai/docs/pytorch/stable/starter/installation.html)\n",
    "\n",
    "```bash\n",
    "# Pip\n",
    "python -m pip install lightning\n",
    "\n",
    "# Conda\n",
    "conda install lightning -c conda-forge\n",
    "```\n",
    "\n",
    "### Основные возможности\n",
    "\n",
    "Как уже было сказано выше, цель данного фреймворка избавить от необходимости написания лишнего кода. \n",
    "\n",
    "- **Тренировка и Валидация**: Lightning автоматизирует переключение между тренировочным и валидационным режимами (а так же test и predict режимы), контролирует циклы обучения, и предоставляет полезные коллбеки(способ модифицировать цикл обучения/валидации или тестирования добавлением нескольких строк кода, более подробно рассмотрим далее).\n",
    "- **GPU и TPU**: Lightning обеспечивает простое управление ресурсами, автоматизируя развертывание модели на доступные устройства (GPUs/TPUs).\n",
    "- **Масштабирование**: с легкостью (реально одной строчкой) можно использовать режимы распределенного обучения (и даже инференса)\n",
    "- **Модульность и переиспользуемость**:\n",
    "    - `LightningModule`: Объединяет в себе модель, оптимизатор и логику тренировочного цикла. Может быть использован для предсказаний, а также сохранен и загружен без проблем.\n",
    "    - `Callbacks`: Позволяют встраивать дополнительную логику в тренировочный цикл без изменения исходного кода модели. А так же есть зоопарк коробчных и сторонних колбеков, отвечающих практически за всю логику, которую вам захочется добавить\n",
    "- **Разделение логики**:\n",
    "    - Research vs Engineering: Lightning позволяет разработчикам сосредотачиваться на исследовательской части работы, выделяя логику тренировочного цикла и обработку данных в отдельные абстракции.\n",
    "- **Совместимость и Интеграция**:\n",
    "    - `LightningModule`: наследуется от torch.nn.Module. Lightning предоставляет естественный переход от стандартного кода PyTorch, позволяя легко адаптировать существующий код.\n",
    "    - Совместимость с библиотеками: Обширная поддержка различных библиотек и фреймворков для логирования, визуализации и др.\n",
    "- **Безопасность и Отказоустойчивость**:\n",
    "    - Остановка и Возобновление: Возможность остановки обучения и последующего возобновления с того же места.\n",
    "    - Очистка: Автоматическое освобождение ресурсов GPU после тренировки.\n",
    "\n",
    "### Логгирование экспериментов\n",
    "\n",
    "- Логгер (или их список) передается напрямую в `pl.Trainer`\n",
    "- В логгер можно писать через `self.log()` внутри Lightning модулей\n",
    "- Так же в логгер пишут дополнительные коллбеки и плагины, которые вы передаете в `pl.Trainer`\n",
    "- Некоторые из готовых логгеров:\n",
    "    - [CSV Logger](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.csv_logs.html#module-lightning.pytorch.loggers.csv_logs)\n",
    "    - [Mlflow Logger](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.mlflow.html#module-lightning.pytorch.loggers.mlflow)\n",
    "    - [Tensorboard Logger](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.tensorboard.html#module-lightning.pytorch.loggers.tensorboard)\n",
    "    - [Wandb Logger](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.wandb.html#module-lightning.pytorch.loggers.wandb)\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "- Коллбеки передатся в `pl.Trainer` и позволяют выполнить какое-то действие в конкретный момент процесса обучения, не изменяя исходный код модели.\n",
    "- Пользователь может создавать собственные коллбеки, отнаследовавшись от базового `Callback` класса и переписав его методы.\n",
    "- Некоторые полезные коллбеки, которые встроены в Lightning:\n",
    "    - `ModelCheckpoint`: автоматически сохраняет чекпоинты модели в процессе обучения\n",
    "    - `EarlyStopping`: останавливает обучение, когда заданная метрика перестает улучшаться\n",
    "    - `LearningRateMonitor`: сохраняет значения скорости обучения в логгер\n",
    "\n",
    "Посмотрим как это всё работает на практике, обучив немного модифицированную нейронную сеть с прошлого занятия.\n",
    "\n",
    "Загружаем данные: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Часть данных для обучения\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./cifar', download=True, train=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Валидационная / тестовая часть данных\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./cifar', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Посмотрим на несколько картинок из обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(13, 5))\n",
    "for i in range(10):\n",
    "    axs[i//5, i%5].imshow(train_dataset[i][0].permute((1, 2, 0)))\n",
    "    axs[i//5, i%5].axis('off')\n",
    "plt.suptitle(\"картинки из датасета\", y=0.95)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Создадим даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True,)\n",
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Зададим базовый класс модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MySimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Здесь объявляем все слои, которые будем использовать\n",
    "        '''\n",
    "        super(MySimpleModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(3 * 32 * 32, 256)\n",
    "        self.linear2 = nn.Linear(256, 64)\n",
    "        self.linear3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Здесь пишем в коде, в каком порядке какой слой будет применяться\n",
    "        '''\n",
    "        x = self.linear1(nn.Flatten()(x))\n",
    "        x = self.linear2(nn.ReLU()(x))\n",
    "        x = self.linear3(nn.ReLU()(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Теперь начнем использовать преимущества Lightning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint, DeviceStatsMonitor, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MySimpleModelLightning(pl.LightningModule):\n",
    "    def __init__(self, lr=0.01, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.save_hyperparameters() # сохраним гиперпараметры\n",
    "        self.model = MySimpleModel()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        '''Возвращает лосс с 1 шага обучения по батчу'''\n",
    "        _, loss, acc = self.__get_preds_loss_accuracy(batch)\n",
    "\n",
    "        # Логируем лосс и метрику\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_accuracy', acc)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        '''Используется для логирования метрик'''\n",
    "        preds, loss, acc = self.__get_preds_loss_accuracy(batch)\n",
    "\n",
    "        # Логируем лосс и метрику\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', acc)\n",
    "\n",
    "        # Возвращаем предсказания, чтобы использовать их в callback\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''определяет оптимизатор модели'''\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def __get_preds_loss_accuracy(self, batch):\n",
    "        '''вспомогательная функция для шага обучения / валидации'''\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = accuracy(preds, y, 'multiclass', num_classes=self.n_classes)\n",
    "        return preds, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Рассмотрим логгирование более подробно. Разберем логгирование с помощью Tensorboard и MLFlow.\n",
    "\n",
    "Tensorboard является частью Tensorflow, но является отдельным пакетом. Лучше всего подходит для локального логгирования. Он способен:\n",
    "- Отслеживать и визуализировать метрики, например loss и accuracy.\n",
    "- Визуализировать вычислительный граф (параметры и слои).\n",
    "- Просматривать гистограммы весов, сдвигов и то, как они меняются со временем.\n",
    "- Строить проекции промежуточных представлений в пространства с более низкой размерностью\n",
    "- Отображать картинки, текст, аудиоданные.\n",
    "\n",
    "MLFLow - open source MLOps платформа. Основные возможности:\n",
    "\n",
    "- Отслеживание экспериментов: код, данные, параметры, результаты\n",
    "- Проекты: позволяет запаковать data science код для воспроизведения на любой платформе\n",
    "- Модели: позволяет деплоить модели на сервер\n",
    "- Model registry: позволяет хранить, описывать и управлять моделями с центральном репозитории\n",
    "\n",
    "**Установка:**\n",
    "### Установка\n",
    "\n",
    "```bash\n",
    "# Tensorboard\n",
    "pip install tensorboard\n",
    "\n",
    "# MLFlow\n",
    "pip install mlflow\n",
    "```\n",
    "\n",
    "**Полезные ссылки:**\n",
    "\n",
    "[MLFlow](https://mlflow.org) - сайт MLFlow, на котором можно почитать про примеры применения, посмотреть как get started guide, так и полную документацию\n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/tensorboard/get_started) - Гайд по Tensorboard\n",
    "\n",
    "[Lightning logging](https://lightning.ai/docs/pytorch/stable/extensions/logging.html) - Логгирование в lightning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Инициализация логгеров\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"lightning_logs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Инициализируем модель. С помощью `ModelCheckpoint` можно периодически сохранять модель / выполнять callback, отслеживая некоторую величину. Показателем того, что модель стала лучше (параметр `monitor`), может быть любая метрика, сохраненная с помощью `log()` или `log_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# инициализируем модель\n",
    "simple_model = MySimpleModelLightning()\n",
    "\n",
    "# Создаем чекпоинтер\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_accuracy', mode='max')\n",
    "# Создаем мониторинг ресурсов\n",
    "device_stats = DeviceStatsMonitor()\n",
    "# Создаем коллбек для остановки обучения в случае отсутствия улучшений:\n",
    "early_stopping = EarlyStopping('val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Можно задать свою функцию callback, которая наследуется от `pytorch_lightning.callbacks.Callback`. Можно после прогона батча на валидации дополнительно сохранять какие-то данные, например, предсказания модели. Здесь мы логируем 20 картинок и предсказания для них."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Создаем Trainer: нужно указать логгер, все функции callback, ускоритель и количество эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=tb_logger,                    \n",
    "    callbacks=[checkpoint_callback,\n",
    "               early_stopping,\n",
    "               device_stats],\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Осталось обучить модель с помощью `train.fit`. Видим, как нам не нужно отдельно прописывать функцию обучения &mdash; Pytorch Lightning сделал это за нас. Также видим статистику по параметрам нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(simple_model, train_batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Интерактивный просмотр логов\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Задание 2**\n",
    "\n",
    "Добавьте слои BatchNorm и Dropout в нейронную сеть там, где это необходимо, проведите минимум 3 эксперимента по обучению модели с использованием PyTorch Lightning и Tensorboard с разными параметрами (например можно изменить learning rate, число нейронов на скрытом слое, оптимизатор, вероятность отключения нейронов на слое, размер батча). Как изменения повлияли на скорость обучения и финальное качество модели? Сделайте выводы.\n",
    "\n",
    "При сдаче задания вместе с ноутбуком прикрепите заархивированную папку с логами tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
