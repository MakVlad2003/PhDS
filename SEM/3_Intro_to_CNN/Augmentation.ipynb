{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "1e1df45bb6ce7932"
   },
   "source": [
    "# ML в Биологии\n",
    "## Аугментация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "ce2173feccae16b4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import glob\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.2, style='whitegrid')\n",
    "\n",
    "# device_num = 0\n",
    "# torch.cuda.set_device(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47edc4a0c392be62",
    "outputId": "3aaabd1a-f205-4cf3-f0dc-8cfa7db1e3f3"
   },
   "outputs": [],
   "source": [
    "device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "2092d6ef7451cbc0"
   },
   "source": [
    "## 1. Аугментация <a id='augmentations'> </a>\n",
    "\n",
    "![](https://sun9-5.userapi.com/c857216/v857216818/1815e6/OxQ8e3-o0oU.jpg)\n",
    "\n",
    "**Дополнение данных / Аугментация данных / Data augmentations** &mdash; это метод, направленный на увеличение размеров обучающей выборки. Дополнение обучающей выборки разнообразными, \"хорошими\" и \"плохими\" примерами, позволяет получить модель более устойчивую на тестовых данных, так как для неё в тестовых данных будет меньше \"неожиданностей\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "16eabad3b353da87"
   },
   "source": [
    "Благодаря модулю `torchvision.transforms` агументации можно делать очень просто. Про все реализованные в библиотеке преобразования можно почитать [здесь](https://pytorch.org/vision/stable/transforms.html#transforms-scriptability). Мы рассмотрим наиболее распространенные классы аугментаций.\n",
    "\n",
    "* `RandomAffine(degrees, translate=None, scale=None, shear=None, interpolation=<InterpolationMode.NEAREST: 'nearest'>, fill=0, fillcolor=None, resample=None)` &mdash; **случайное афинное преобразование** с сохранением центра. `degrees` &mdash; градус вращения. `translate` &mdash; смещение. `scale` &mdash; масштаб. Подробнее в документации.\n",
    "\n",
    "\n",
    "* `ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)` &mdash; *случайное* изменение **яркости** / brightness, **контраста** / contrast, **насыщенности** / saturation и **тонов** / hue цветов. Если на вход приходит torch.Tensor, то его размерность дожна быть `[..., 3, H, W]`. Если PIL.Image, то без альфа-канала. Каждый из параметров может быть быть задан в виде float числа: param, или пары float чисел: min, max. Значение парметра выбирается случайно из отрезка `[1 - param, 1 + param]` или `[min, max]` для brightness, contrast, saturation. Значение парметра должно быть нотрицательным. Значение парметра hue выбирается случайно из отрезка `[-hue, hue]` или `[min, max]`. При этом значение 0<= `hue <= 0.5` or `-0.5 <= min <= max <= 0.5`.  \n",
    "\n",
    "\n",
    "* `CenterCrop(size)` &mdash; вырезает **прямоугольную область** размером `size[0] x size[1]`, если size задан туплом, если `size` задан числом &mdash; `size x size` **из центра картинки**.\n",
    "\n",
    "\n",
    "* `GaussianBlur(kernel_size, sigma)` &mdash; *случайное* **гауссовское размытие изображения**. `kernel_size` &mdash; размер гауссовского ядра. `sigma` &mdash; стандартное отклонение. `sigma` может быть задано в виде чила, тогда парметр фиксирован, или в виде тупла in, max, тогда оно выбирается случайно из отрезка `[min, max]`.  \n",
    "\n",
    "\n",
    "* `Grayscale(num_output_channels=1)` и `RandomGrayscale`(p=0.1) &mdash; неслучайная и *случайная* **трансформации картинки в ч/б формат**. Grayscale имеет парметр `num_output_channels`, который означет количество каналов на выходе, он может быть равен 1 или 3. RandomGrayscale имеет парметр p, который равен вероятности применения преобразования. Тензор на выхоже будет иметь столько же каналов, сколько тензор на входе.   \n",
    "\n",
    "\n",
    "* `Normalize(mean, std, inplace=False)` &mdash; **нормализация тензора картинки** с заданными средним и отклонением для каждого канала. То есть `mean = (mean[1], ..., mean[n])`, `std = (std[1], ..., std[n])`, где `n` &mdash; количество каналов. Не поддерживает PIL.Image формат!   \n",
    "\n",
    "\n",
    "* `RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=<InterpolationMode.BILINEAR: 'bilinear'>)` &mdash; **случайное обрезание картинки** со случайным выбором размера и соотношения сторон и последующим **увеличеним картинки до первонального размера**.  \n",
    "\n",
    "* `Resize(size, interpolation=<InterpolationMode.BILINEAR: 'bilinear'>)`  &mdash; **изменение размеров кратинки**. Если `size` задан числом, то наименьшая из размерностей картинки приобретает размер `size`. Иначе, если размер задан парой, то размер картинки становится равным `size[0] x size[1]`.\n",
    "\n",
    "Для того, чтобы получить преобразование, которого нет в модуле torchvision.transforms можно использовать `Lambda` преобразование. Например, получить гауссовский шум на изображении можно так:\n",
    "```\n",
    "Lambda(lambda x : x + torch.randn_like(x))\n",
    "```\n",
    "\n",
    "Выше перечисленные трансформации применяются к данным типа PIL.Image или torch.Tensor,на выходе выдают соотвествующий формат. Для того, чтобы в через тарнсформации получить PIL.Image, можно использовать класс `ToPILImage`, для того, чтобы получить torch.Tensor &mdash; `ToTensor`. Эти классы в методе forward могут использовать torch.Tensor, np.ndarray и PIL.Image, np.ndarray соотвественно.\n",
    "\n",
    "Чтобы объединить несколько трансформаций можно использовать `Compose`(transforms), где transforms &mdash; список из объектов коассов преобразований."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "a9b6df9dbea8cc6b"
   },
   "source": [
    "### Практика по аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "8b78a03d5eda509b"
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5e406a50bb3c30c",
    "outputId": "9409c294-a081-460e-d02c-66c009bdd8d4"
   },
   "outputs": [],
   "source": [
    "# скачиваем изображения\n",
    "! wget https://upload.wikimedia.org/wikipedia/ru/thumb/2/24/Lenna.png/1920px-Lenna.png\n",
    "! wget https://miptstats.github.io/images/logo_bottom.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "ad6c9e8eb3116849"
   },
   "source": [
    "Выберите 3 преобразования, которые вам понравятся [отсюда](https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-and-torch-tensor) 3 преобразования, прмените его к исходному изображению и объясните, что это преобразование делает.\n",
    "\n",
    "Пример применения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "f8a6d089065c80a6"
   },
   "outputs": [],
   "source": [
    "# transform = transforms.RandomAffine(degrees=75)\n",
    "# transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "b718822e89c1bf7b"
   },
   "outputs": [],
   "source": [
    "#Поворачивает картинку\n",
    "# transform = transforms.RandomRotation(degrees = 50)\n",
    "# transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "WK0-na0RUcVZ"
   },
   "outputs": [],
   "source": [
    "# Искажает изображение \"в перспективе\"\n",
    "# transform = transforms.RandomPerspective()\n",
    "# transform(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "NKjdJfl3VKNR"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "1. `transforms.RandomAffine(degrees=75)`\n",
    "\n",
    "   Поворачивает изображение на случайный угол (до 75 градусов) и может масштабировать или смещать его. Это помогает модели научиться распознавать объекты, независимо от их ориентации.\n",
    "\n",
    "2. `transforms.RandomRotation(degrees=50)`\n",
    "\n",
    "   Поворачивает изображение на случайный угол в диапазоне от -50 до +50 градусов. Это добавляет вариативность данных и делает модель более устойчивой к разным ракурсам объекта.\n",
    "\n",
    "3. `transforms.RandomPerspective()`\n",
    "\n",
    "   Искажает изображение с применением перспективной трансформации, создавая эффект изменения точки обзора. Это позволяет модели быть более адаптивной к изображениям, снятым под разными углами.\n",
    "\n",
    "Все эти трансформации увеличивают разнообразие обучающей выборки, что помогает улучшить обобщающие способности модели."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
