{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "11b9c0ff"
   },
   "source": [
    "# <a href=\"https://thetahat.ru/courses/ph-ds-2024-aut\">Phystech@DataScience</a>\n",
    "## Домашнее задание 7\n",
    "\n",
    "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_pds_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно ноутбук в формате `ipynb`.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "* **Код из рассказанных на занятиях ноутбуков можно использовать без ограничений.**\n",
    "\n",
    "**Правила оформления теоретических задач:**\n",
    "\n",
    "* Решения необходимо прислать одним из следующих способов:\n",
    "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
    "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
    "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
    "  * в виде $\\LaTeX$ в markdown-ячейках.\n",
    "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
    "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
    "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Задача 1: 30 баллов\n",
    "\n",
    "* Задача 2: 30 баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "aae8ae20"
   },
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: phds_hw7\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "69110754",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.3)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "a8d8cc6d"
   },
   "source": [
    "*Напоминаем, что во всех заданиях нашего курса, да и в реальной жизни, если вы получаете какие-то результаты, то надо сделать вывод!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "eb0a7b78",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задача 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "c157cfa8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В этой задаче вам предлагается исследовать зависимость качества предсказаний модели случайного леса в зависимости от различных гиперпараметров на примере задаче регрессии. Будем использовать класс `RandomForestRegressor` библиотеки `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "83e48837acb0c2f5"
   },
   "source": [
    "В качестве данных возьмём следующие датасеты:\n",
    "\n",
    "**Профиль физика:** https://www.kaggle.com/datasets/khsamaha/solar-flares-rhessi. Будем предсказывать длительность солнечных вспышек. Используйте файл с данными до 2018 года.\n",
    "\n",
    "**Профиль биология:** https://archive.ics.uci.edu/dataset/1/abalone. Будем предсказывать возраст моллюсков.\n",
    "\n",
    "*Совет.* При отладке кода используйте небольшую часть данных. Финальные вычисления проведите на полных данных. Для отслеживания времени работы можно использовать `tqdm` в циклах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "5bfa0dbc5fd11f86"
   },
   "source": [
    "#### Загрузка и предобработка данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "397e905be6716e60"
   },
   "source": [
    "**Биология:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "954e9880496013d5",
    "outputId": "44b0a383-1832-4c66-bf4f-0c18e38fa7a8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('abalone.data', names=['Sex', 'Length', 'Diameter', 'Height', 'Whole weight',\n",
    "                                          'Shucked weight', 'Viscera weight', 'Shell weight',\n",
    "                                          'Rings'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "cea5c6df02894f20"
   },
   "source": [
    "Уберем категориальный признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "a6aadf0f16f468e9"
   },
   "outputs": [],
   "source": [
    "data = data.drop('Sex', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "id": "1a3e9cd3f8503970"
   },
   "outputs": [],
   "source": [
    "X = data.drop('Rings', axis=1)\n",
    "y = data['Rings'] + 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "d0fa3220",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Разбейте данные на обучающую выборку и на валидацию, выделив на валидацию 25% данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "id": "196b8c10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "e6d4a24b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрите, как изменяется качество леса в зависимости от выбранных параметров. Для этого постройте графики зависимости MSE на тестовой выборке от количества деревьев (от 1 до 100) и от максимальной глубины дерева (от 3 до 25). Когда варьируете один из параметров, в качестве другого берите значение по умолчанию. Для того, чтобы исследовать зависимость от количества деревьев, обучите лес **один** раз и посчитайте предсказания каждого отдельного дерева в лесу. После этого используйте усреднение первых $k$ предсказаний в качестве ответа для $k$ деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "44b45571",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cum_metric(model, metric, x_test, y_test):\n",
    "    '''\n",
    "    Считает значение метрики в зависимости от количества деревьев в модели случайного леса.\n",
    "\n",
    "    В этой функции для оценки влияния количества деревьев мы обучаем случайный лес один раз\n",
    "    и вычисляем предсказания каждого дерева. Далее усредняем первые k предсказаний для k деревьев.\n",
    "\n",
    "    Параметры:\n",
    "    model (RandomForestRegressor): Обученная модель случайного леса.\n",
    "    metric (function): Функция для вычисления метрики (например, mean_squared_error).\n",
    "    x_test (array-like): Признаки тестовой выборки.\n",
    "    y_test (array-like): Метки тестовой выборки.\n",
    "\n",
    "    Возвращает:\n",
    "    numpy.array: Массив значений метрики для каждого числа деревьев от 1 до n_estimators.\n",
    "    '''\n",
    "\n",
    "    predictions_by_estimators = [est.predict(x_test) for est in model.estimators_]\n",
    "    cumpred = np.array(predictions_by_estimators).cumsum(axis=0) / (np.arange(len(predictions_by_estimators)) + 1)[:, np.newaxis]\n",
    "    cumacc = [metric(y_test, pred) for pred in cumpred]\n",
    "    return np.array(cumacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "Ry1lKQ7Z-JOf"
   },
   "source": [
    "Исследование зависимости от количества деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "gUk_eY6R9ic0"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "estimations = cum_metric(forest, mean_squared_error, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "JVebvYm8-K6O"
   },
   "source": [
    "Построение графика MSE от количества деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "1-u1jhNx7Ool",
    "outputId": "6e9a35f3-3298-4575-96b6-0d30462121df"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(range(1, 101), estimations)\n",
    "plt.xlabel('Количество деревьев')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Зависимость MSE от количества деревьев')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "GFcAqm-9-OHR"
   },
   "source": [
    "Исследование зависимости от максимальной глубины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d7e91628719b4089b678c406529cd2c1",
      "2b9228d1696a437f9731d12d7b59a5d9",
      "6f4cf738fffd4e9482ae70d41a63d609",
      "c0116e04300549c8b06b3089da16179b",
      "780d6bc9af49425598bd5e6f8b71e0f0",
      "bbaabecd5fc34303a5c8dd8785fb2608",
      "25691839236a432293d60a4e22051524",
      "492d4e7c3a73452b8e99892748c7b3bc",
      "8f717ec98e2340208498c4edac193765",
      "08f83df7eacb4f7e8de0aca2996824e1",
      "62e67ebfab774abfaff8157ced1db995"
     ]
    },
    "id": "IKEDPWzA7Ovs",
    "outputId": "db864463-86e1-44d6-a4d2-7a93694892f1"
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "depths = np.arange(3, 26)\n",
    "for d in tqdm(depths, desc=\"Максимальная глубина\"):\n",
    "    forest = RandomForestRegressor(max_depth=d, random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "    pred = forest.predict(X_test)\n",
    "    res.append(mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "Vjobbp-R7O3r",
    "outputId": "0f1df3f1-4c92-4db9-adb2-8f207534489d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(depths, res)\n",
    "plt.xlabel('max depth')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Зависимость MSE от max_depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "f8c19413",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Основываясь на полученных графиках, ответьте на следующие вопросы.\n",
    "\n",
    "1. Какие закономерности можно увидеть на построенных графиках? Почему графики получились такими?\n",
    "\n",
    "2. Как изменяется качество предсказаний с увеличением исследуемых параметров, когда эти параметры уже достаточно большие.\n",
    "\n",
    "3. В предыдущем задании вы на практике убедились, что решающее дерево начинает переобучаться при достаточно больших значениях максимальной глубины. Справедливо ли это утверждение для случайного леса? Поясните свой ответ, опираясь на своё знание статистики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "1ed403c1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Сначала ошибка значительно уменьшается, а затем стабилизируется, оставаясь на одном уровне при дальнейшем увеличении параметра. Однако при изменении количества деревьев ошибка на плато выглядит более сглаженной по сравнению с ситуацией, когда изменяется максимальная глубина.\n",
    "\n",
    "Это можно объяснить тем, что при увеличении количества деревьев в лесу снижается дисперсия (variance), и усреднённый результат «голосования» деревьев становится все более стабильным, так что добавление новых деревьев уже мало влияет на ошибку.\n",
    "\n",
    "В то же время чрезмерно большая глубина деревьев может привести к нестабильности и переобучению отдельных деревьев. Благодаря усреднению результатов, типичного для случайного леса, выраженного переобучения всей модели не происходит (каждое дерево переобучается «по-своему», и эти ошибки компенсируют друг друга), поэтому ошибка колеблется около некоторого среднего уровня, хотя некоторая нестабильность все же присутствует.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "d3848ca4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обучите случайный лес с параметрами по умолчанию и выведите mse на тестовой выборке. Проведите эксперимент 3 раза. Почему результаты отличаются?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "8bd41b9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mses = []\n",
    "for _ in range(3):\n",
    "    forest = RandomForestRegressor()\n",
    "    forest.fit(X_train, y_train)\n",
    "    pred = forest.predict(X_test)\n",
    "    mses.append(mse(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuW4Wj4-7b3-",
    "outputId": "99bf2cad-ad8b-4346-ec9c-27f62624b8a3"
   },
   "outputs": [],
   "source": [
    "print(*mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "0f35f0d6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Выборка случайным образом разбивается на подвыборки, фичи для ветвления деревьев тоже выбираются случайным образом. Так что от перезапуска могут получаться немного различные результаты из-за этих стохастических компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "88f44d15",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Было бы неплохо определиться с тем, какое количество деревьев нужно использовать и какой максимальной глубины они будут. Подберите оптимальные значения `max_depth` и `n_estimators` с помощью кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "eb31c297",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "      'max_depth': [5, 6, 7, 8, 9, 10],\n",
    "      'n_estimators': [100, 117, 118, 119, 120, 121, 122]\n",
    "  }\n",
    "\n",
    "tree_gridsearch = GridSearchCV(estimator, param_grid, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "DbkXgMjI7hDv",
    "outputId": "6e4f6b49-10a0-4cb1-9869-c0bb758216cf"
   },
   "outputs": [],
   "source": [
    "tree_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "0bcfa52b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Выведите найденные оптимальные параметры. Поясните, согласуются ли наблюдения с теорией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddb5a319",
    "outputId": "8c3cd8bb-539c-401b-ece2-616ba637b0a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "187db28c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Вывод:**\n",
    "\n",
    "В целом, результаты соответствуют теории: для хорошего качества нужно большое количество деревьев с достаточной глубиной. Однако чрезмерная глубина также нежелательна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "ee2edd85",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Зафиксируем эти оптимальные значения параметров и в дальнейшим будем их использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "6df3fb57",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_depth = 8\n",
    "n_estimators = 119"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "a7dc3e80",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Оценим качество предсказаний обученного решающего леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a047820",
    "outputId": "d5a52e1a-2720-4b92-91aa-413f9e56a7d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "pred = forest.predict(X_test)\n",
    "\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "b87f8bf0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Исследуйте зависимость метрики `mse` от количества признаков, по которым происходит разбиение в вершине дерева. Поскольку количество признаков в датасете не очень большое (их 8), то можно перебрать все возможные варианты количества признаков, использующихся при разбиении вершин.\n",
    "\n",
    "Не забывайте делать пояснения и выводы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "6173847c98d043038d1afeb541b7a378",
      "8d2fcfddea9049faa572954ab068e35d",
      "b968e03d62cd45afa10479d88e32f6be",
      "a764e800a54846a4bb9bd8d373482078",
      "9f0b85a37bd246f6b0fb4ded2c0559c8",
      "1bbc9bdddd2447c0a6525135e0b81211",
      "edfe522e0e9440ffb84b751a19d063b4",
      "15d9c83cac374c3db1428664a5bbe74d",
      "49ee9984457049519655830e84b2165b",
      "6f42dce849a544f7a3254eee70291159",
      "c47c111e1b8e4e8e86923440a8d7e888"
     ]
    },
    "id": "6ccb672a",
    "outputId": "03b620bf-6845-46ba-98f0-a7cc071bcd05",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_res = []\n",
    "test_res = []\n",
    "max_features = np.arange(1, 8)\n",
    "\n",
    "for m in tqdm(max_features):\n",
    "    forest = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=m)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = forest.predict(X_train)\n",
    "    train_res.append(mse(y_train, train_pred))\n",
    "\n",
    "    test_pred = forest.predict(X_test)\n",
    "    test_res.append(mse(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "id": "533615ce",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Постройте график зависимости метрики mse на `test` и `train` в зависимости от числа признаков, использующихся при разбиении в каждой вершине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "e9af4768",
    "outputId": "a401f75f-790e-404b-8ecd-07a0b8a608ac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "plt.plot(max_features, train_res, label='train')\n",
    "plt.plot(max_features, test_res, label='test')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "c172d982",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Почему график получился таким? Как зависит разнообразие деревьев от величины `n_features`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "319d0f79",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Линия для обучающей выборки снижается с увеличением числа признаков, что логично: чем больше признаков разрешено использовать при одном ветвлении, тем легче модели запомнить данные.\n",
    "\n",
    "Кривая для тестовой выборки выходит на плато (а затем может даже немного повыситься), так как увеличенное количество признаков ведёт к переобучению.\n",
    "\n",
    "Кроме того, при слишком большом числе доступных признаков не происходит эффективного снижения дисперсии, так как деревья в лесу становятся более похожими друг на друга: при выборе признаков для ветвления рандомизация теряется, если доступны все признаки.\n",
    "\n",
    "Поэтому в качестве оптимального значения выберу 3 признака, после которых кривая теста, как мне показалось, вышла на плато."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "5651b0de",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Зафиксируйте наилучшие гиперпараметры.\n",
    "\n",
    "Проведите исследование скорости обучения и предсказания.\n",
    "\n",
    "Засеките время обучения и предсказания, например, с помощью модуля `time`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cf45009",
    "outputId": "10a6fb1f-e974-4c50-a4cb-fa2c7cf22fe8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 3\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "\n",
    "start_fit = time()\n",
    "forest.fit(X_train, y_train)\n",
    "stop_fit = time()\n",
    "\n",
    "start_pred = time()\n",
    "pred = forest.predict(X_test)\n",
    "stop_pred = time()\n",
    "\n",
    "print(f\"Fitting time: {round(stop_fit - start_fit, 5)} секунд\\nPrediction time: {round(stop_pred - start_pred, 5)} секунд\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "21e46193",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посчитайте среднюю глубину дерева в случайном лесе. Используйте функцию `get_depth()` для отдельных деревьев леса.\n",
    "Посчитайте среднее количество листьев, используя функцию `get_n_leaves()` для отдельных деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "id": "24b930ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "depths = []\n",
    "leaves = []\n",
    "\n",
    "for tree in forest.estimators_:\n",
    "    depths.append(tree.get_depth())\n",
    "    leaves.append(tree.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCAW1dR0CxgI",
    "outputId": "5948a611-b7d4-41cd-e6fd-ec4f6a9c14fd"
   },
   "outputs": [],
   "source": [
    "print(f'Средняя глубина дерева: {np.mean(depths)}\\nСреднее количество листьев: {np.mean(leaves)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "id": "3be9c8cf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сделайте выводы. Какие деревья обычно используются в случайном лесу? Как вы предполагаете, как от этого зависит скорость обучения и предсказания?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "c2f4fc46",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Деревья обычно используются с большой глубиной (здесь средняя глубина достигает максимально возможной) и с множеством разветвлений. Поэтому обучение занимает значительное время, и предсказания тоже выполняются не мгновенно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {
    "id": "ea705c18",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Исследуйте важности признаков для следующих случаев:\n",
    "\n",
    "\n",
    "\n",
    "*   Решающее  дерево\n",
    "*   Случайный лес\n",
    "*   Лес из первых 5-10 деревьев случайного леса из предыдущего пункта.\n",
    "\n",
    "Также проанализируйте качество моделей выше.\n",
    "\n",
    "Сделайте выводы. Отличаются ли посчитанные важности? Есть ли связь важностей признаков и качества моделей? О чем говорят посчитанные важности признаков?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "id": "58690019",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_importance(model, columns, title):\n",
    "\n",
    "    global_importances = pd.Series(model.feature_importances_, index=columns)\n",
    "    global_importances.sort_values(ascending=True, inplace=True)\n",
    "    global_importances.plot.barh(color='green')\n",
    "\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qtfRGEd77h0",
    "outputId": "2d2659db-80db-4fb3-8a28-762fe8e6389b"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "pred = tree.predict(X_test)\n",
    "\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "MTU1q-Ee7-dD",
    "outputId": "0e586afe-f54c-4a86-91d4-96e1e60ae6d5"
   },
   "outputs": [],
   "source": [
    "plot_importance(tree, X_train.columns, 'Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UE94MTN77_o9",
    "outputId": "a81e6ff0-8c9c-452a-c9cd-62d8315e4d52"
   },
   "outputs": [],
   "source": [
    "pred = forest.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "e_wzg4y08BMa",
    "outputId": "dd1e467c-8dce-48c5-fe3b-d56f1458e0e4"
   },
   "outputs": [],
   "source": [
    "plot_importance(forest, X_train.columns, 'Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YG-Xm3-k8DXs",
    "outputId": "a7994fc6-d0f9-45e2-e98e-216a010c9f16"
   },
   "outputs": [],
   "source": [
    "forest.estimators_ = forest.estimators_[:5]\n",
    "pred = forest.predict(X_test)\n",
    "mse(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "3scE2FgZ8GCo",
    "outputId": "c9b90a2b-bcf5-403f-eeed-24f90a016d26"
   },
   "outputs": [],
   "source": [
    "plot_importance(forest, X_train.columns, 'Small forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "id": "f83426e7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "Признак \"Shell weight\" остаётся главным в каждом случае, вероятно, он объективно наиболее значим для предсказания.\n",
    "\n",
    "Дальнейшие позиции по важности у дерева и леса распределяются по-разному. Также заметно, что лес придаёт немного больше значения остальным признакам по сравнению с деревом, создавая впечатление, что дерево почти полностью опирается на два ведущих признака.\n",
    "\n",
    "Если строить предсказания, используя только первые 5 деревьев леса, соотношение важностей признаков заметно меняется: важность становится почти одинаковой для первых трёх признаков, а признаки со второго по четвёртый меняются местами. Важность же последних двух признаков остаётся практически неизменной.\n",
    "\n",
    "Связь между значимостями признаков, вероятно, есть, но она не очевидна. У дерева и леса распределения важностей схожи, но значение MSE отличается почти в два раза."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {
    "id": "d8e9ac60",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задача 2\n",
    "\n",
    "На лекции была получена формула bias-variance разложения для беггинга. Проведите эксперимент, в котором выясните, насколько уменьшается разброс (variance-компонента) беггинг-модели на 100 базовых моделях по отношению к одной базовой модели. Используйте данные из предыдущей задачи. Рассмотрите случайный лес и беггинг на моделях ридж-регрессии.\n",
    "\n",
    "\n",
    "Для реализации данного эксперимента используйте класс беггинг-модели\n",
    "`sklearn.ensemble.BaggingRegressor` , у которого используйте следующие поля:\n",
    "* `base_estimator` — базовая модель;\n",
    "* `max_features` — количество признаков для каждой базовой модели;\n",
    "* `n_estimators` — количество базовых моделей.\n",
    "\n",
    "Для решения задачи потребуется оценить корреляции предсказаний на тестовой выборке базовых моделей, входящих в состав беггинг-модели. Эти модели можно получить с помощью поля `estimators_` у обученной беггинг-модели. Корреляции моделей можно смотреть как корреляции векторов их предсказаний.\n",
    "\n",
    "Насколько уменьшается разброс в каждом случае? Для каждого случая постройте также матрицу корреляций предсказаний базовых моделей и гистограмму по ним. Какую оценку коэффициента корреляции вы используете и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "id": "xIDQlVvb8PJX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "eef8f7ec",
    "outputId": "b5807e85-d948-42fd-9515-de105f356c63"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100, max_features=3)\n",
    "bagging = BaggingRegressor(estimator=Ridge(), max_features=3, n_estimators=100)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "id": "a45e3404"
   },
   "outputs": [],
   "source": [
    "bagging_preds = []\n",
    "forest_preds = []\n",
    "\n",
    "for est, feature_inds in zip(bagging.estimators_, bagging.estimators_features_):\n",
    "    features = X_test.columns[feature_inds]\n",
    "    pred = est.predict(X_test[features])\n",
    "    bagging_preds.append(pred)\n",
    "\n",
    "for est in forest.estimators_:\n",
    "    pred = est.predict(X_test)\n",
    "    forest_preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "id": "e1f01f59"
   },
   "outputs": [],
   "source": [
    "length = len(bagging_preds)\n",
    "bag_corr_matrix = np.zeros((length, length))\n",
    "for_corr_matrix = np.zeros((length, length))\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        bag_corr = pearsonr(bagging_preds[i], bagging_preds[j])[0]\n",
    "        for_corr = pearsonr(forest_preds[i], forest_preds[j])[0]\n",
    "        bag_corr_matrix[i, j] = bag_corr\n",
    "        for_corr_matrix[i, j] = for_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "8eb99bfe",
    "outputId": "cea45198-0012-44f1-a4c1-14d6f2a6592e"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "im1 = axs[0].imshow(bag_corr_matrix)\n",
    "plt.colorbar(im1, ax=axs[0])\n",
    "axs[0].set_title(\"Ridge Bagging\")\n",
    "\n",
    "im2 = axs[1].imshow(for_corr_matrix)\n",
    "plt.colorbar(im2, ax=axs[1])\n",
    "axs[1].set_title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {
    "id": "db37d959"
   },
   "source": [
    "Отмечаем, что отдельные модели в Ridge-бэггинге демонстрируют высокую корреляцию, то есть бэггинг не снижает корреляцию между базовыми моделями в случае линейной регрессии.\n",
    "\n",
    "Для случайного леса, напротив, наблюдается низкая корреляция между деревьями, что соответствует ожидаемому результату — модели в лесу остаются относительно независимыми.\n",
    "\n",
    "Для оценки коэффициента корреляции был использован коэффициент корреляции Пирсона, так как линейная мера корреляции здесь вполне уместна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {
    "id": "5ab617e2"
   },
   "source": [
    "Посмотрим теперь на гистограммы распределения коэффиуицентов корреляции в обоих случаях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "091100e9",
    "outputId": "4371fa2c-3e54-40e1-c49d-92fdf8a68008"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "axs[0].hist(bag_corr_matrix.reshape(-1))\n",
    "axs[0].set_title(\"Ridge Bagging\")\n",
    "\n",
    "axs[1].hist(for_corr_matrix.reshape(-1))\n",
    "axs[1].set_title(\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {
    "id": "bb92f87a"
   },
   "source": [
    "Для ridge bagging корреляция охватывает широкий диапазон высоких значений (от 0.75 до 1), тогда как у случайного леса значения корреляции сосредоточены в диапазоне 0.4 - 0.6. Это также подтверждается визуально на тепловой карте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {
    "id": "b790f4a9"
   },
   "source": [
    "Теперь проведем эксперимент: обучим n моделей для бэггинга, обычной ridge-регрессии, случайного леса и решающего дерева. Оценим разброс значений MSE на тестовой выборке, полученных этими моделями, и вычислим variance для результатов.\n",
    "\n",
    "Отметим, что для ridge-регрессии будем обучать модель на случайно выбранных трех признаках, чтобы сохранить аналогичность с бэггингом (и обеспечить наличие разброса, так как в противном случае у линейной регрессии получится одно значение, ведь веса подбираются аналитически)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d0278c4db47a495d8a96030c7f2c5d16",
      "fb3c4d3b113642ec9683630644e563a5",
      "05149698e7eb48fe903e942c47bd9c16",
      "c7b2c946124e4e3db023030346c5a63e",
      "7e344990fab64609afdf3ca6f3ff7e35",
      "223ead65714545cfae4b0607e4723efc",
      "2bc77de5378543ab8ae5bd27b220e2c5",
      "ffecf6cb474347be9a79743aa776c2c7",
      "6bbc20d490634f8dbe581fb783c6d1e2",
      "b8967cc53bdd44069306f8370f14b79b",
      "e25a9cd0b13444c3ac08dc7beb21f805"
     ]
    },
    "id": "9c393405",
    "outputId": "af8e6a29-6b11-4a88-fc12-abdb53730b45"
   },
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "\n",
    "bag_results = []\n",
    "ridge_results = []\n",
    "\n",
    "for_results = []\n",
    "tree_results = []\n",
    "\n",
    "for _ in tqdm(range(n_iter)):\n",
    "    bagging = BaggingRegressor(estimator=Ridge(), max_features=3, n_estimators=100, n_jobs=-1)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    bag_results.append(mse(y_test, bagging.predict(X_test)))\n",
    "\n",
    "    ridge = Ridge()\n",
    "    feature_indexes = np.random.choice(7, 3)\n",
    "    features = X_train.columns[feature_indexes]\n",
    "    ridge.fit(X_train[features], y_train)\n",
    "    ridge_results.append(mse(y_test, ridge.predict(X_test[features])))\n",
    "\n",
    "    forest = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "    forest.fit(X_train, y_train)\n",
    "    for_results.append(mse(y_test, forest.predict(X_test)))\n",
    "\n",
    "    tree = DecisionTreeRegressor()\n",
    "    tree.fit(X_train, y_train)\n",
    "    tree_results.append(mse(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "id": "6e2c9bf8"
   },
   "outputs": [],
   "source": [
    "bag_results  = np.array(bag_results)\n",
    "tree_results = np.array(tree_results)\n",
    "for_results  = np.array(for_results)\n",
    "ridge_results = np.array(ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "392961f3",
    "outputId": "7771c29e-fc4e-4737-dad0-b2de4c06b7ce"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 12))\n",
    "fig.suptitle('Распределение MSE для различных моделей', fontsize=16)\n",
    "\n",
    "plot_data = [\n",
    "    (bag_results, 'Bagging', axs[0][0]),\n",
    "    (ridge_results, 'Ridge', axs[0][1]),\n",
    "    (for_results, 'Random Forest', axs[1][0]),\n",
    "    (tree_results, 'Decision Tree', axs[1][1])\n",
    "]\n",
    "\n",
    "colors = ['skyblue', 'lightgreen', 'salmon', 'plum']\n",
    "alpha = 0.75\n",
    "\n",
    "for (data, title, ax), color in zip(plot_data, colors):\n",
    "    ax.hist(data, bins=30, color=color, edgecolor='black', alpha=alpha)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.axvline(r_mse, color='red', linestyle='--', linewidth=1.5, label='Single Ridge MSE')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('MSE')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {
    "id": "a0e398b3"
   },
   "source": [
    "Линейная регрессия возвращает только одно значение MSE, что вполне логично — веса вычисляются аналитически и не зависят от перезапуска. У бэггинга наблюдается небольшой разброс результатов, однако это не критично, поскольку у линейной регрессии и так очень низкая дисперсия.\n",
    "\n",
    "В случае ридж-регрессии, обученной на случайных трех признаках, дисперсия становится заметной и даже превышает таковую у решающего дерева. Бэггинг успешно справляется с этой дисперсией, уменьшая её почти в 100 раз, что соответствует идеальному сценарию. Однако, такой подход умышленно ухудшает исходную линейную регрессию, что вызывает вопрос о целесообразности. Ошибка для одной ридж-регрессии, обученной на всех признаках, оказывается ниже, чем для всех моделей, использующих меньшее количество признаков, и, что более важно, ниже, чем у бэггинга.\n",
    "\n",
    "При сравнении решающего дерева и случайного леса видно, что ошибка у дерева в целом выше, а также наблюдается больший разброс значений: у леса результаты колеблются вокруг среднего с разбросом примерно ±0.1, тогда как у дерева разброс составляет ±0.75.\n",
    "\n",
    "Как видно ниже, дисперсия в случайном лесе уменьшилась примерно в 50 раз по сравнению с деревом. Это хороший результат, но всё же не идеальный, поскольку деревья в лесу немного скоррелированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16a70b23",
    "outputId": "5511a71f-6f63-4b5d-87b5-fd8ebed26103"
   },
   "outputs": [],
   "source": [
    "print(f'Variance of bagging MSE score:       {bag_results.var()}')\n",
    "print(f'Variance of ridge MSE score:         {ridge_results.var()}')\n",
    "print(f'Variance of forest MSE score:        {for_results.var()}')\n",
    "print(f'Variance of decision tree MSE score: {tree_results.var()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {
    "id": "09857c7c"
   },
   "source": [
    "**Вывод:**\n",
    "\n",
    "Мы убедились, что использование бэггинга для деревьев приносит хорошие результаты, тогда как для линейных моделей это оказывается неэффективным, а порой даже контрпродуктивным. Случайный лес действительно улучшает качество предсказаний и снижает дисперсию по сравнению с решающим деревом. В то же время бэггинг на линейных регрессиях показал худшие результаты по сравнению с простой линейной регрессией. Кроме того, в линейной регрессии нет значительной дисперсии, так как модель слишком проста, чтобы это имело смысл."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
